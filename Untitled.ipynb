{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\"\n",
    "r = requests.get(zip_file_url)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall(\"E:\\\\TensorflowDeveloperCertification\\\\catsdogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('E:\\\\TensorflowDeveloperCertification\\\\catsdogs/PetImages/Cat/')))\n",
    "print(len(os.listdir('E:\\\\TensorflowDeveloperCertification\\\\catsdogs/PetImages/Dog/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use os.mkdir to create your directories\n",
    "# You will need a directory for cats-v-dogs, and subdirectories for training\n",
    "# and testing. These in turn will need subdirectories for 'cats' and 'dogs'\n",
    "try:\n",
    "    #YOUR CODE GOES HERE\n",
    "    os.mkdir('E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs')\n",
    "    os.mkdir('E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs/training')\n",
    "    os.mkdir('E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs/testing')\n",
    "    os.mkdir('E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs/training/cats')\n",
    "    os.mkdir('E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs/training/dogs')\n",
    "    os.mkdir('E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs/testing/cats')\n",
    "    os.mkdir('E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs/testing/dogs')\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "  # YOUR CODE STARTS HERE\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        \n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "            \n",
    "            \n",
    "    \n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    testing_set = shuffled_set[-testing_length:]\n",
    "    \n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "        \n",
    "    for filename in testing_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TESTING + filename\n",
    "        copyfile(this_file, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_SOURCE_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs/PetImages/Cat/\"\n",
    "TRAINING_CATS_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs/training/cats\"\n",
    "TESTING_CATS_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs/testing/cats\"\n",
    "DOG_SOURCE_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs/PetImages/Dog/\"\n",
    "TRAINING_DOGS_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs/training/dogs/\"\n",
    "TESTING_DOGS_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs/training/dogs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "  # YOUR CODE STARTS HERE\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        \n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "            \n",
    "            \n",
    "    \n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    testing_set = shuffled_set[-testing_length:]\n",
    "    \n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "        \n",
    "    for filename in testing_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TESTING + filename\n",
    "        copyfile(this_file, destination)\n",
    "        \n",
    "CAT_SOURCE_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs/PetImages/Cat/\"\n",
    "TRAINING_CATS_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs/training/cats\"\n",
    "TESTING_CATS_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs/testing/cats\"\n",
    "DOG_SOURCE_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs/PetImages/Dog/\"\n",
    "TRAINING_DOGS_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs/training/dogs/\"\n",
    "TESTING_DOGS_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs/training/dogs/\"\n",
    "\n",
    "split_size = .9\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_SOURCE_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs\\\\PetImages\\\\Cat\\\\\"\n",
    "TRAINING_CATS_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs\\\\cats-v-dogs\\\\training\\\\cats\"\n",
    "TESTING_CATS_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs/cats-v-dogs\\\\testing\\\\cats\"\n",
    "DOG_SOURCE_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs\\\\PetImages\\\\Dog\"\n",
    "TRAINING_DOGS_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs\\\\cats-v-dogs\\\\training\\\\dogs\"\n",
    "TESTING_DOGS_DIR = \"E:\\\\TensorflowDeveloperCertification\\\\catsdogs\\\\cats-v-dogs\\\\training\\\\dogs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = []\n",
    "for filename in os.listdir(CAT_SOURCE_DIR):\n",
    "    file = CAT_SOURCE_DIR + filename\n",
    "    #print(file)\n",
    "    #print (filename)\n",
    "    if os.path.getsize(file) > 0:\n",
    "        files.append(filename)\n",
    "    else:\n",
    "        print(filename + \" is zero length, so ignoring.\")\n",
    "    \n",
    "training_length = int(len(files) * SPLIT_SIZE)\n",
    "testing_length = int(len(files) - training_length)\n",
    "shuffled_set = random.sample(files, len(files))\n",
    "training_set = shuffled_set[0:training_length]\n",
    "testing_set = shuffled_set[-testing_length:]\n",
    "print(training_length)\n",
    "print(testing_length)\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_SIZE = 0.9\n",
    "training_length = int(len(CAT_SOURCE_DIR) * SPLIT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CAT_SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_length = int(len(CAT_SOURCE_DIR) - training_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "shuffled_set = random.sample(CAT_SOURCE_DIR, len(CAT_SOURCE_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shuffled_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = shuffled_set[0:training_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = shuffled_set[-testing_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CAT_SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "for filename in training_set:\n",
    "    this_file = CAT_SOURCE_DIR + filename\n",
    "    destination = TRAINING_CATS_DIR + filename\n",
    "    print(this_file)\n",
    "    print(destination)\n",
    "    print(filename)\n",
    "    copyfile(this_file, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in training_set:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    with open(filename) as training_file:\n",
    "        csv_reader = csv.reader(training_file, delimiter=',')\n",
    "        first_line = True\n",
    "        temp_images = []\n",
    "        temp_labels = []\n",
    "        for row in csv_reader:\n",
    "            if first_line:\n",
    "                # print(\"Ignoring first line\")\n",
    "                first_line = False\n",
    "            else:\n",
    "                temp_labels.append(row[0])\n",
    "                image_data = row[1:785]\n",
    "                image_data_as_array = np.array_split(image_data, 28)\n",
    "                temp_images.append(image_data_as_array)\n",
    "        images = np.array(temp_images).astype('float')\n",
    "        labels = np.array(temp_labels).astype('float')\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"sign_mnist_train.csv\", newline='') as training_file:\n",
    "    csv_reader = csv.reader(training_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        row1 = next(csv_reader)\n",
    "        print(row1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"E:\\\\TensorflowDeveloperCertification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_reader = csv.reader(\"sign_mnist_train.csv\", delimiter=',') \n",
    "first_line = True\n",
    "temp_images = []\n",
    "temp_labels = []\n",
    "\n",
    "\n",
    "        \n",
    "with open('sign_mnist_train.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    row1 = next(reader)  # gets the first line\n",
    "    print(row1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"E:\\\\TensorflowDeveloperCertification\\\\sign_mnist_train/sign_mnist_train.csv\")\n",
    "test = pd.read_csv(\"E:\\\\TensorflowDeveloperCertification\\\\sign_mnist_test/sign_mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"E:\\\\TensorflowDeveloperCertification\\\\Tensorflow _Ravi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "with open(\"bbc-text.csv\", 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        labels.append(row[0])\n",
    "        #print(labels)\n",
    "        sentences.append(row[1])\n",
    "        #print(sentences)\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "for word in stopwords:\n",
    "    token = \" \" + word + \" \"\n",
    "    #print(token)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"E:\\\\TensorflowDeveloperCertification\\\\Learning/bbc-text.csv\", 'r') as training_file:\n",
    "    csv_reader = csv.reader(training_file, delimiter=',')\n",
    "    first_line = True\n",
    "    for row in csv_reader:\n",
    "        if first_line:\n",
    "            # print(\"Ignoring first line\")\n",
    "            first_line = False\n",
    "        else:\n",
    "            print(row[0])\n",
    "            print(row[1])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "sentences = []\n",
    "labels = []\n",
    "with open(\"E:\\\\TensorflowDeveloperCertification\\\\Learning/bbc-text.csv\", 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        labels.append(row[0])\n",
    "        sentence = row[1]\n",
    "        for word in stopwords:\n",
    "            token = \" \" + word + \" \"\n",
    "            sentence = sentence.replace(token, \" \")\n",
    "            #print(sentences)\n",
    "            sentence = sentence.replace(\"  \", \" \")\n",
    "        sentences.append(sentence)\n",
    "print(len(sentences))\n",
    "print(sentences[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "with open(\"E:\\\\TensorflowDeveloperCertification\\\\Learning/bbc-text.csv\", 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        print(row[0])\n",
    "        print(row[1])\n",
    "        for word in stopwords:\n",
    "            token = \" \" + word + \" \"\n",
    "            print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
