{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True, as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = info.features['text'].encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "#train_dataset = train_dataset.padded_batch(BATCH_SIZE, train_dataset.output_shapes)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(train_dataset))\n",
    "\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 128)         66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 635,329\n",
      "Trainable params: 635,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/391 [============>.................] - ETA: 2:47:42 - loss: 0.6932 - accuracy: 0.500 - ETA: 1:02:34 - loss: 0.6929 - accuracy: 0.515 - ETA: 1:06:36 - loss: 0.6923 - accuracy: 0.526 - ETA: 1:13:31 - loss: 0.6926 - accuracy: 0.525 - ETA: 1:17:39 - loss: 0.6925 - accuracy: 0.526 - ETA: 1:15:18 - loss: 0.6926 - accuracy: 0.525 - ETA: 1:22:33 - loss: 0.6923 - accuracy: 0.527 - ETA: 1:23:48 - loss: 0.6920 - accuracy: 0.530 - ETA: 1:20:45 - loss: 0.6918 - accuracy: 0.531 - ETA: 1:17:31 - loss: 0.6917 - accuracy: 0.532 - ETA: 1:22:59 - loss: 0.6918 - accuracy: 0.532 - ETA: 1:25:23 - loss: 0.6918 - accuracy: 0.532 - ETA: 1:24:03 - loss: 0.6917 - accuracy: 0.532 - ETA: 1:26:27 - loss: 0.6917 - accuracy: 0.532 - ETA: 1:27:32 - loss: 0.6916 - accuracy: 0.533 - ETA: 1:29:06 - loss: 0.6916 - accuracy: 0.533 - ETA: 1:28:31 - loss: 0.6915 - accuracy: 0.533 - ETA: 1:25:56 - loss: 0.6915 - accuracy: 0.533 - ETA: 1:25:27 - loss: 0.6915 - accuracy: 0.533 - ETA: 1:23:15 - loss: 0.6915 - accuracy: 0.533 - ETA: 1:22:06 - loss: 0.6915 - accuracy: 0.533 - ETA: 1:21:16 - loss: 0.6915 - accuracy: 0.532 - ETA: 1:22:40 - loss: 0.6915 - accuracy: 0.532 - ETA: 1:20:32 - loss: 0.6915 - accuracy: 0.532 - ETA: 1:19:20 - loss: 0.6915 - accuracy: 0.532 - ETA: 1:19:49 - loss: 0.6915 - accuracy: 0.532 - ETA: 1:19:35 - loss: 0.6914 - accuracy: 0.531 - ETA: 1:19:34 - loss: 0.6914 - accuracy: 0.531 - ETA: 1:18:17 - loss: 0.6914 - accuracy: 0.531 - ETA: 1:16:36 - loss: 0.6914 - accuracy: 0.531 - ETA: 1:15:44 - loss: 0.6914 - accuracy: 0.531 - ETA: 1:14:46 - loss: 0.6913 - accuracy: 0.531 - ETA: 1:15:00 - loss: 0.6913 - accuracy: 0.531 - ETA: 1:14:04 - loss: 0.6913 - accuracy: 0.531 - ETA: 1:14:45 - loss: 0.6913 - accuracy: 0.531 - ETA: 1:14:23 - loss: 0.6912 - accuracy: 0.531 - ETA: 1:14:13 - loss: 0.6912 - accuracy: 0.531 - ETA: 1:12:56 - loss: 0.6912 - accuracy: 0.531 - ETA: 1:12:29 - loss: 0.6911 - accuracy: 0.531 - ETA: 1:12:05 - loss: 0.6911 - accuracy: 0.532 - ETA: 1:11:04 - loss: 0.6910 - accuracy: 0.532 - ETA: 1:11:14 - loss: 0.6910 - accuracy: 0.532 - ETA: 1:12:04 - loss: 0.6909 - accuracy: 0.533 - ETA: 1:13:21 - loss: 0.6907 - accuracy: 0.533 - ETA: 1:13:46 - loss: 0.6906 - accuracy: 0.533 - ETA: 1:13:17 - loss: 0.6904 - accuracy: 0.534 - ETA: 1:24:45 - loss: 0.6902 - accuracy: 0.534 - ETA: 1:25:58 - loss: 0.6900 - accuracy: 0.535 - ETA: 1:25:44 - loss: 0.6898 - accuracy: 0.536 - ETA: 1:25:02 - loss: 0.6896 - accuracy: 0.536 - ETA: 1:26:42 - loss: 0.6894 - accuracy: 0.537 - ETA: 1:26:09 - loss: 0.6891 - accuracy: 0.537 - ETA: 1:26:38 - loss: 0.6888 - accuracy: 0.538 - ETA: 1:26:17 - loss: 0.6886 - accuracy: 0.539 - ETA: 1:26:12 - loss: 0.6883 - accuracy: 0.539 - ETA: 1:25:58 - loss: 0.6880 - accuracy: 0.540 - ETA: 1:25:26 - loss: 0.6876 - accuracy: 0.541 - ETA: 1:25:01 - loss: 0.6873 - accuracy: 0.541 - ETA: 1:25:26 - loss: 0.6869 - accuracy: 0.542 - ETA: 1:24:17 - loss: 0.6865 - accuracy: 0.543 - ETA: 1:26:10 - loss: 0.6861 - accuracy: 0.544 - ETA: 1:25:31 - loss: 0.6856 - accuracy: 0.545 - ETA: 1:24:36 - loss: 0.6851 - accuracy: 0.545 - ETA: 1:24:23 - loss: 0.6846 - accuracy: 0.546 - ETA: 1:23:38 - loss: 0.6842 - accuracy: 0.547 - ETA: 1:23:11 - loss: 0.6837 - accuracy: 0.548 - ETA: 1:23:11 - loss: 0.6833 - accuracy: 0.549 - ETA: 1:23:00 - loss: 0.6828 - accuracy: 0.550 - ETA: 1:22:02 - loss: 0.6823 - accuracy: 0.550 - ETA: 1:21:53 - loss: 0.6818 - accuracy: 0.551 - ETA: 1:21:46 - loss: 0.6813 - accuracy: 0.552 - ETA: 1:21:03 - loss: 0.6808 - accuracy: 0.553 - ETA: 1:20:22 - loss: 0.6803 - accuracy: 0.554 - ETA: 1:19:22 - loss: 0.6798 - accuracy: 0.554 - ETA: 1:19:07 - loss: 0.6794 - accuracy: 0.555 - ETA: 1:18:42 - loss: 0.6790 - accuracy: 0.556 - ETA: 1:18:27 - loss: 0.6786 - accuracy: 0.557 - ETA: 1:18:13 - loss: 0.6782 - accuracy: 0.558 - ETA: 1:17:39 - loss: 0.6779 - accuracy: 0.558 - ETA: 1:17:06 - loss: 0.6775 - accuracy: 0.559 - ETA: 1:16:57 - loss: 0.6771 - accuracy: 0.560 - ETA: 1:16:29 - loss: 0.6768 - accuracy: 0.560 - ETA: 1:16:26 - loss: 0.6764 - accuracy: 0.561 - ETA: 1:16:04 - loss: 0.6761 - accuracy: 0.562 - ETA: 1:15:46 - loss: 0.6757 - accuracy: 0.562 - ETA: 1:15:44 - loss: 0.6754 - accuracy: 0.563 - ETA: 1:15:14 - loss: 0.6751 - accuracy: 0.564 - ETA: 1:14:38 - loss: 0.6748 - accuracy: 0.564 - ETA: 1:14:10 - loss: 0.6744 - accuracy: 0.565 - ETA: 1:13:42 - loss: 0.6741 - accuracy: 0.566 - ETA: 1:13:00 - loss: 0.6738 - accuracy: 0.567 - ETA: 1:12:51 - loss: 0.6735 - accuracy: 0.567 - ETA: 1:12:26 - loss: 0.6732 - accuracy: 0.568 - ETA: 1:11:48 - loss: 0.6729 - accuracy: 0.569 - ETA: 1:11:27 - loss: 0.6726 - accuracy: 0.569 - ETA: 1:10:55 - loss: 0.6723 - accuracy: 0.570 - ETA: 1:10:33 - loss: 0.6720 - accuracy: 0.570 - ETA: 1:09:55 - loss: 0.6717 - accuracy: 0.571 - ETA: 1:09:58 - loss: 0.6714 - accuracy: 0.572 - ETA: 1:09:23 - loss: 0.6711 - accuracy: 0.572 - ETA: 1:08:58 - loss: 0.6708 - accuracy: 0.573 - ETA: 1:08:40 - loss: 0.6705 - accuracy: 0.574 - ETA: 1:08:29 - loss: 0.6702 - accuracy: 0.574 - ETA: 1:07:56 - loss: 0.6699 - accuracy: 0.575 - ETA: 1:07:35 - loss: 0.6696 - accuracy: 0.576 - ETA: 1:07:23 - loss: 0.6693 - accuracy: 0.576 - ETA: 1:06:57 - loss: 0.6689 - accuracy: 0.577 - ETA: 1:06:36 - loss: 0.6686 - accuracy: 0.577 - ETA: 1:06:11 - loss: 0.6683 - accuracy: 0.578 - ETA: 1:06:04 - loss: 0.6680 - accuracy: 0.579 - ETA: 1:05:38 - loss: 0.6676 - accuracy: 0.579 - ETA: 1:05:19 - loss: 0.6673 - accuracy: 0.580 - ETA: 1:04:55 - loss: 0.6669 - accuracy: 0.581 - ETA: 1:05:18 - loss: 0.6666 - accuracy: 0.581 - ETA: 1:05:06 - loss: 0.6663 - accuracy: 0.582 - ETA: 1:04:55 - loss: 0.6659 - accuracy: 0.582 - ETA: 1:05:01 - loss: 0.6656 - accuracy: 0.583 - ETA: 1:04:33 - loss: 0.6652 - accuracy: 0.584 - ETA: 1:04:01 - loss: 0.6649 - accuracy: 0.584 - ETA: 1:03:45 - loss: 0.6646 - accuracy: 0.585 - ETA: 1:03:37 - loss: 0.6642 - accuracy: 0.585 - ETA: 1:03:15 - loss: 0.6639 - accuracy: 0.586 - ETA: 1:02:57 - loss: 0.6635 - accuracy: 0.586 - ETA: 1:02:42 - loss: 0.6632 - accuracy: 0.587 - ETA: 1:02:30 - loss: 0.6628 - accuracy: 0.588 - ETA: 1:02:08 - loss: 0.6625 - accuracy: 0.588 - ETA: 1:01:57 - loss: 0.6621 - accuracy: 0.589 - ETA: 1:01:38 - loss: 0.6618 - accuracy: 0.589 - ETA: 1:01:25 - loss: 0.6614 - accuracy: 0.590 - ETA: 1:00:58 - loss: 0.6611 - accuracy: 0.590 - ETA: 1:00:53 - loss: 0.6608 - accuracy: 0.591 - ETA: 1:00:37 - loss: 0.6604 - accuracy: 0.591 - ETA: 1:00:12 - loss: 0.6601 - accuracy: 0.592 - ETA: 1:00:10 - loss: 0.6597 - accuracy: 0.593 - ETA: 59:49 - loss: 0.6594 - accuracy: 0.5935  - ETA: 1:47:25 - loss: 0.6591 - accuracy: 0.594 - ETA: 1:47:02 - loss: 0.6587 - accuracy: 0.594 - ETA: 1:46:28 - loss: 0.6584 - accuracy: 0.595 - ETA: 1:45:40 - loss: 0.6581 - accuracy: 0.595 - ETA: 1:45:13 - loss: 0.6577 - accuracy: 0.596 - ETA: 1:44:28 - loss: 0.6574 - accuracy: 0.596 - ETA: 1:43:56 - loss: 0.6571 - accuracy: 0.597 - ETA: 1:42:58 - loss: 0.6567 - accuracy: 0.597 - ETA: 1:42:11 - loss: 0.6564 - accuracy: 0.598 - ETA: 1:42:05 - loss: 0.6561 - accuracy: 0.598 - ETA: 1:42:07 - loss: 0.6558 - accuracy: 0.599 - ETA: 1:41:19 - loss: 0.6554 - accuracy: 0.599 - ETA: 1:40:30 - loss: 0.6551 - accuracy: 0.600 - ETA: 1:39:52 - loss: 0.6548 - accuracy: 0.600 - ETA: 1:39:10 - loss: 0.6545 - accuracy: 0.601 - ETA: 1:39:01 - loss: 0.6542 - accuracy: 0.601 - ETA: 1:38:21 - loss: 0.6538 - accuracy: 0.602 - ETA: 1:37:45 - loss: 0.6535 - accuracy: 0.602 - ETA: 1:37:25 - loss: 0.6532 - accuracy: 0.602 - ETA: 1:36:56 - loss: 0.6529 - accuracy: 0.603 - ETA: 1:36:27 - loss: 0.6525 - accuracy: 0.603 - ETA: 1:35:34 - loss: 0.6522 - accuracy: 0.604 - ETA: 1:35:12 - loss: 0.6519 - accuracy: 0.604 - ETA: 1:34:22 - loss: 0.6516 - accuracy: 0.605 - ETA: 1:33:44 - loss: 0.6512 - accuracy: 0.605 - ETA: 1:33:03 - loss: 0.6509 - accuracy: 0.606 - ETA: 1:32:29 - loss: 0.6506 - accuracy: 0.606 - ETA: 1:31:58 - loss: 0.6503 - accuracy: 0.607 - ETA: 1:31:21 - loss: 0.6499 - accuracy: 0.607 - ETA: 1:30:42 - loss: 0.6496 - accuracy: 0.608 - ETA: 1:30:03 - loss: 0.6493 - accuracy: 0.608 - ETA: 1:29:28 - loss: 0.6489 - accuracy: 0.608 - ETA: 1:28:52 - loss: 0.6486 - accuracy: 0.609 - ETA: 1:28:13 - loss: 0.6483 - accuracy: 0.609 - ETA: 1:27:34 - loss: 0.6479 - accuracy: 0.6102\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/391 [=========================>....] - ETA: 1:27:05 - loss: 0.6476 - accuracy: 0.610 - ETA: 1:26:24 - loss: 0.6473 - accuracy: 0.611 - ETA: 1:25:50 - loss: 0.6470 - accuracy: 0.611 - ETA: 1:25:07 - loss: 0.6467 - accuracy: 0.611 - ETA: 1:24:37 - loss: 0.6464 - accuracy: 0.612 - ETA: 1:24:00 - loss: 0.6460 - accuracy: 0.612 - ETA: 1:23:21 - loss: 0.6457 - accuracy: 0.613 - ETA: 1:22:46 - loss: 0.6454 - accuracy: 0.613 - ETA: 1:22:19 - loss: 0.6451 - accuracy: 0.614 - ETA: 1:21:47 - loss: 0.6448 - accuracy: 0.614 - ETA: 1:21:06 - loss: 0.6445 - accuracy: 0.614 - ETA: 1:20:31 - loss: 0.6442 - accuracy: 0.615 - ETA: 1:19:56 - loss: 0.6439 - accuracy: 0.615 - ETA: 1:19:22 - loss: 0.6436 - accuracy: 0.616 - ETA: 1:18:46 - loss: 0.6433 - accuracy: 0.616 - ETA: 1:18:06 - loss: 0.6430 - accuracy: 0.616 - ETA: 1:17:28 - loss: 0.6426 - accuracy: 0.617 - ETA: 1:17:01 - loss: 0.6423 - accuracy: 0.617 - ETA: 1:16:26 - loss: 0.6420 - accuracy: 0.618 - ETA: 1:15:51 - loss: 0.6417 - accuracy: 0.618 - ETA: 1:15:32 - loss: 0.6414 - accuracy: 0.618 - ETA: 1:15:10 - loss: 0.6411 - accuracy: 0.619 - ETA: 1:14:42 - loss: 0.6408 - accuracy: 0.619 - ETA: 1:14:16 - loss: 0.6405 - accuracy: 0.620 - ETA: 1:13:48 - loss: 0.6402 - accuracy: 0.620 - ETA: 1:13:15 - loss: 0.6399 - accuracy: 0.620 - ETA: 1:12:50 - loss: 0.6396 - accuracy: 0.621 - ETA: 1:12:14 - loss: 0.6393 - accuracy: 0.621 - ETA: 1:11:40 - loss: 0.6390 - accuracy: 0.622 - ETA: 1:11:13 - loss: 0.6387 - accuracy: 0.622 - ETA: 1:10:41 - loss: 0.6384 - accuracy: 0.622 - ETA: 1:10:11 - loss: 0.6381 - accuracy: 0.623 - ETA: 1:09:40 - loss: 0.6378 - accuracy: 0.623 - ETA: 1:09:08 - loss: 0.6375 - accuracy: 0.624 - ETA: 1:08:42 - loss: 0.6372 - accuracy: 0.624 - ETA: 1:08:15 - loss: 0.6369 - accuracy: 0.624 - ETA: 1:07:42 - loss: 0.6366 - accuracy: 0.625 - ETA: 1:07:16 - loss: 0.6363 - accuracy: 0.625 - ETA: 1:06:49 - loss: 0.6360 - accuracy: 0.625 - ETA: 1:06:17 - loss: 0.6357 - accuracy: 0.626 - ETA: 1:05:49 - loss: 0.6354 - accuracy: 0.626 - ETA: 1:05:24 - loss: 0.6351 - accuracy: 0.627 - ETA: 1:04:55 - loss: 0.6348 - accuracy: 0.627 - ETA: 1:04:25 - loss: 0.6345 - accuracy: 0.627 - ETA: 1:03:58 - loss: 0.6342 - accuracy: 0.628 - ETA: 1:03:25 - loss: 0.6339 - accuracy: 0.628 - ETA: 1:02:56 - loss: 0.6336 - accuracy: 0.628 - ETA: 1:02:27 - loss: 0.6333 - accuracy: 0.629 - ETA: 1:02:01 - loss: 0.6330 - accuracy: 0.629 - ETA: 1:01:38 - loss: 0.6327 - accuracy: 0.629 - ETA: 1:01:13 - loss: 0.6324 - accuracy: 0.630 - ETA: 1:00:41 - loss: 0.6322 - accuracy: 0.630 - ETA: 1:00:10 - loss: 0.6319 - accuracy: 0.630 - ETA: 59:48 - loss: 0.6316 - accuracy: 0.6313  - ETA: 59:18 - loss: 0.6313 - accuracy: 0.631 - ETA: 58:57 - loss: 0.6310 - accuracy: 0.631 - ETA: 58:37 - loss: 0.6307 - accuracy: 0.632 - ETA: 58:10 - loss: 0.6305 - accuracy: 0.632 - ETA: 57:45 - loss: 0.6302 - accuracy: 0.633 - ETA: 57:22 - loss: 0.6299 - accuracy: 0.633 - ETA: 56:58 - loss: 0.6296 - accuracy: 0.633 - ETA: 56:30 - loss: 0.6293 - accuracy: 0.634 - ETA: 56:06 - loss: 0.6290 - accuracy: 0.634 - ETA: 55:38 - loss: 0.6288 - accuracy: 0.634 - ETA: 55:07 - loss: 0.6285 - accuracy: 0.635 - ETA: 54:38 - loss: 0.6282 - accuracy: 0.635 - ETA: 54:09 - loss: 0.6279 - accuracy: 0.635 - ETA: 53:40 - loss: 0.6276 - accuracy: 0.636 - ETA: 53:14 - loss: 0.6274 - accuracy: 0.636 - ETA: 52:48 - loss: 0.6271 - accuracy: 0.636 - ETA: 52:23 - loss: 0.6268 - accuracy: 0.636 - ETA: 51:56 - loss: 0.6265 - accuracy: 0.637 - ETA: 51:26 - loss: 0.6263 - accuracy: 0.637 - ETA: 51:02 - loss: 0.6260 - accuracy: 0.637 - ETA: 50:34 - loss: 0.6257 - accuracy: 0.638 - ETA: 50:11 - loss: 0.6255 - accuracy: 0.638 - ETA: 49:47 - loss: 0.6252 - accuracy: 0.638 - ETA: 49:22 - loss: 0.6249 - accuracy: 0.639 - ETA: 48:56 - loss: 0.6246 - accuracy: 0.639 - ETA: 48:33 - loss: 0.6244 - accuracy: 0.639 - ETA: 48:07 - loss: 0.6241 - accuracy: 0.640 - ETA: 47:44 - loss: 0.6238 - accuracy: 0.640 - ETA: 47:17 - loss: 0.6236 - accuracy: 0.640 - ETA: 46:52 - loss: 0.6233 - accuracy: 0.641 - ETA: 46:29 - loss: 0.6230 - accuracy: 0.641 - ETA: 46:03 - loss: 0.6228 - accuracy: 0.641 - ETA: 45:35 - loss: 0.6225 - accuracy: 0.641 - ETA: 45:08 - loss: 0.6222 - accuracy: 0.642 - ETA: 44:44 - loss: 0.6220 - accuracy: 0.642 - ETA: 44:17 - loss: 0.6217 - accuracy: 0.642 - ETA: 43:51 - loss: 0.6214 - accuracy: 0.643 - ETA: 43:27 - loss: 0.6212 - accuracy: 0.643 - ETA: 43:01 - loss: 0.6209 - accuracy: 0.643 - ETA: 42:38 - loss: 0.6206 - accuracy: 0.644 - ETA: 42:17 - loss: 0.6204 - accuracy: 0.644 - ETA: 41:53 - loss: 0.6201 - accuracy: 0.644 - ETA: 41:31 - loss: 0.6198 - accuracy: 0.645 - ETA: 41:07 - loss: 0.6196 - accuracy: 0.645 - ETA: 40:43 - loss: 0.6193 - accuracy: 0.645 - ETA: 40:19 - loss: 0.6190 - accuracy: 0.645 - ETA: 39:55 - loss: 0.6188 - accuracy: 0.646 - ETA: 39:30 - loss: 0.6185 - accuracy: 0.646 - ETA: 39:10 - loss: 0.6183 - accuracy: 0.646 - ETA: 38:46 - loss: 0.6180 - accuracy: 0.647 - ETA: 38:22 - loss: 0.6177 - accuracy: 0.647 - ETA: 37:57 - loss: 0.6175 - accuracy: 0.647 - ETA: 37:34 - loss: 0.6172 - accuracy: 0.647 - ETA: 37:13 - loss: 0.6170 - accuracy: 0.648 - ETA: 36:48 - loss: 0.6167 - accuracy: 0.648 - ETA: 36:26 - loss: 0.6164 - accuracy: 0.648 - ETA: 36:02 - loss: 0.6162 - accuracy: 0.649 - ETA: 35:42 - loss: 0.6159 - accuracy: 0.649 - ETA: 35:21 - loss: 0.6157 - accuracy: 0.649 - ETA: 34:58 - loss: 0.6154 - accuracy: 0.649 - ETA: 34:36 - loss: 0.6151 - accuracy: 0.650 - ETA: 34:15 - loss: 0.6149 - accuracy: 0.650 - ETA: 33:52 - loss: 0.6146 - accuracy: 0.650 - ETA: 33:28 - loss: 0.6144 - accuracy: 0.651 - ETA: 33:07 - loss: 0.6141 - accuracy: 0.651 - ETA: 32:44 - loss: 0.6139 - accuracy: 0.651 - ETA: 32:20 - loss: 0.6136 - accuracy: 0.651 - ETA: 31:57 - loss: 0.6134 - accuracy: 0.652 - ETA: 31:37 - loss: 0.6131 - accuracy: 0.652 - ETA: 31:16 - loss: 0.6129 - accuracy: 0.652 - ETA: 30:53 - loss: 0.6126 - accuracy: 0.652 - ETA: 30:32 - loss: 0.6123 - accuracy: 0.653 - ETA: 30:08 - loss: 0.6121 - accuracy: 0.653 - ETA: 29:46 - loss: 0.6119 - accuracy: 0.653 - ETA: 29:24 - loss: 0.6116 - accuracy: 0.653 - ETA: 29:04 - loss: 0.6114 - accuracy: 0.654 - ETA: 28:44 - loss: 0.6111 - accuracy: 0.654 - ETA: 28:23 - loss: 0.6109 - accuracy: 0.654 - ETA: 28:01 - loss: 0.6106 - accuracy: 0.655 - ETA: 27:41 - loss: 0.6104 - accuracy: 0.655 - ETA: 27:18 - loss: 0.6101 - accuracy: 0.655 - ETA: 26:57 - loss: 0.6099 - accuracy: 0.655 - ETA: 26:37 - loss: 0.6097 - accuracy: 0.656 - ETA: 26:17 - loss: 0.6094 - accuracy: 0.656 - ETA: 25:56 - loss: 0.6092 - accuracy: 0.656 - ETA: 25:35 - loss: 0.6089 - accuracy: 0.656 - ETA: 25:14 - loss: 0.6087 - accuracy: 0.657 - ETA: 24:55 - loss: 0.6085 - accuracy: 0.657 - ETA: 24:34 - loss: 0.6082 - accuracy: 0.657 - ETA: 24:13 - loss: 0.6080 - accuracy: 0.657 - ETA: 23:52 - loss: 0.6078 - accuracy: 0.658 - ETA: 23:32 - loss: 0.6075 - accuracy: 0.658 - ETA: 23:11 - loss: 0.6073 - accuracy: 0.658 - ETA: 22:52 - loss: 0.6071 - accuracy: 0.658 - ETA: 22:31 - loss: 0.6068 - accuracy: 0.659 - ETA: 22:12 - loss: 0.6066 - accuracy: 0.659 - ETA: 21:52 - loss: 0.6064 - accuracy: 0.659 - ETA: 21:30 - loss: 0.6061 - accuracy: 0.659 - ETA: 21:10 - loss: 0.6059 - accuracy: 0.660 - ETA: 20:50 - loss: 0.6057 - accuracy: 0.660 - ETA: 20:34 - loss: 0.6055 - accuracy: 0.660 - ETA: 20:15 - loss: 0.6052 - accuracy: 0.660 - ETA: 19:55 - loss: 0.6050 - accuracy: 0.661 - ETA: 19:35 - loss: 0.6048 - accuracy: 0.661 - ETA: 19:16 - loss: 0.6045 - accuracy: 0.661 - ETA: 18:56 - loss: 0.6043 - accuracy: 0.661 - ETA: 18:36 - loss: 0.6041 - accuracy: 0.662 - ETA: 18:17 - loss: 0.6039 - accuracy: 0.662 - ETA: 17:58 - loss: 0.6036 - accuracy: 0.662 - ETA: 17:38 - loss: 0.6034 - accuracy: 0.662 - ETA: 17:18 - loss: 0.6032 - accuracy: 0.662 - ETA: 17:02 - loss: 0.6030 - accuracy: 0.663 - ETA: 16:42 - loss: 0.6027 - accuracy: 0.663 - ETA: 16:23 - loss: 0.6025 - accuracy: 0.663 - ETA: 16:03 - loss: 0.6023 - accuracy: 0.663 - ETA: 15:44 - loss: 0.6021 - accuracy: 0.664 - ETA: 15:24 - loss: 0.6019 - accuracy: 0.664 - ETA: 15:05 - loss: 0.6016 - accuracy: 0.664 - ETA: 14:46 - loss: 0.6014 - accuracy: 0.664 - ETA: 14:27 - loss: 0.6012 - accuracy: 0.665 - ETA: 14:12 - loss: 0.6010 - accuracy: 0.6652"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - ETA: 13:53 - loss: 0.6008 - accuracy: 0.665 - ETA: 13:34 - loss: 0.6006 - accuracy: 0.665 - ETA: 13:14 - loss: 0.6004 - accuracy: 0.665 - ETA: 12:54 - loss: 0.6002 - accuracy: 0.666 - ETA: 12:35 - loss: 0.6000 - accuracy: 0.666 - ETA: 12:15 - loss: 0.5998 - accuracy: 0.666 - ETA: 11:56 - loss: 0.5997 - accuracy: 0.666 - ETA: 11:37 - loss: 0.5995 - accuracy: 0.666 - ETA: 11:18 - loss: 0.5993 - accuracy: 0.667 - ETA: 11:00 - loss: 0.5991 - accuracy: 0.667 - ETA: 10:41 - loss: 0.5989 - accuracy: 0.667 - ETA: 10:22 - loss: 0.5987 - accuracy: 0.667 - ETA: 10:03 - loss: 0.5985 - accuracy: 0.667 - ETA: 9:45 - loss: 0.5983 - accuracy: 0.668 - ETA: 9:26 - loss: 0.5982 - accuracy: 0.66 - ETA: 9:08 - loss: 0.5980 - accuracy: 0.66 - ETA: 8:50 - loss: 0.5978 - accuracy: 0.66 - ETA: 8:31 - loss: 0.5976 - accuracy: 0.66 - ETA: 8:12 - loss: 0.5974 - accuracy: 0.66 - ETA: 7:54 - loss: 0.5973 - accuracy: 0.66 - ETA: 7:35 - loss: 0.5971 - accuracy: 0.66 - ETA: 7:18 - loss: 0.5969 - accuracy: 0.66 - ETA: 6:59 - loss: 0.5967 - accuracy: 0.66 - ETA: 6:41 - loss: 0.5966 - accuracy: 0.66 - ETA: 6:22 - loss: 0.5964 - accuracy: 0.67 - ETA: 6:04 - loss: 0.5962 - accuracy: 0.67 - ETA: 5:45 - loss: 0.5960 - accuracy: 0.67 - ETA: 5:27 - loss: 0.5959 - accuracy: 0.67 - ETA: 5:09 - loss: 0.5957 - accuracy: 0.67 - ETA: 12:32 - loss: 0.5955 - accuracy: 0.671 - ETA: 12:05 - loss: 0.5954 - accuracy: 0.671 - ETA: 11:15 - loss: 0.5952 - accuracy: 0.671 - ETA: 10:26 - loss: 0.5950 - accuracy: 0.671 - ETA: 9:37 - loss: 0.5949 - accuracy: 0.671 - ETA: 8:47 - loss: 0.5947 - accuracy: 0.67 - ETA: 7:59 - loss: 0.5945 - accuracy: 0.67 - ETA: 7:10 - loss: 0.5944 - accuracy: 0.67 - ETA: 6:22 - loss: 0.5942 - accuracy: 0.67 - ETA: 5:33 - loss: 0.5941 - accuracy: 0.67 - ETA: 4:45 - loss: 0.5939 - accuracy: 0.67 - ETA: 3:57 - loss: 0.5938 - accuracy: 0.67 - ETA: 3:09 - loss: 0.5936 - accuracy: 0.67 - ETA: 2:22 - loss: 0.5935 - accuracy: 0.67 - ETA: 1:34 - loss: 0.5933 - accuracy: 0.67 - ETA: 47s - loss: 0.5932 - accuracy: 0.6736 - ETA: 0s - loss: 0.5930 - accuracy: 0.673 - 19272s 49s/step - loss: 0.5929 - accuracy: 0.6739 - val_loss: 0.5820 - val_accuracy: 0.6930\n",
      "Epoch 2/10\n",
      " 23/391 [>.............................] - ETA: 1:01:48 - loss: 0.4291 - accuracy: 0.859 - ETA: 1:20:30 - loss: 0.4463 - accuracy: 0.835 - ETA: 57:06 - loss: 0.4593 - accuracy: 0.8194  - ETA: 1:08:50 - loss: 0.4660 - accuracy: 0.809 - ETA: 1:31:58 - loss: 0.4689 - accuracy: 0.804 - ETA: 1:34:34 - loss: 0.4707 - accuracy: 0.800 - ETA: 1:38:55 - loss: 0.4726 - accuracy: 0.798 - ETA: 1:34:21 - loss: 0.4732 - accuracy: 0.796 - ETA: 1:32:17 - loss: 0.4748 - accuracy: 0.795 - ETA: 1:30:10 - loss: 0.4763 - accuracy: 0.793 - ETA: 1:26:23 - loss: 0.4775 - accuracy: 0.792 - ETA: 1:22:05 - loss: 0.4778 - accuracy: 0.792 - ETA: 1:22:04 - loss: 0.4774 - accuracy: 0.792 - ETA: 1:20:41 - loss: 0.4773 - accuracy: 0.792 - ETA: 1:22:35 - loss: 0.4771 - accuracy: 0.792 - ETA: 1:26:42 - loss: 0.4771 - accuracy: 0.792 - ETA: 1:26:51 - loss: 0.4770 - accuracy: 0.791 - ETA: 1:25:14 - loss: 0.4768 - accuracy: 0.791 - ETA: 1:24:14 - loss: 0.4765 - accuracy: 0.791 - ETA: 1:22:35 - loss: 0.4762 - accuracy: 0.791 - ETA: 1:22:15 - loss: 0.4758 - accuracy: 0.792 - ETA: 1:19:24 - loss: 0.4754 - accuracy: 0.792 - ETA: 1:18:01 - loss: 0.4750 - accuracy: 0.7928"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "history = model.fit(train_dataset, epochs=NUM_EPOCHS, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
